import os
import warnings
warnings.filterwarnings("ignore")
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import inspect


import riskfolio as rp
import pyfolio as pf


from scipy.cluster.hierarchy import linkage, dendrogram
from scipy.spatial.distance import squareform


RETURNS_CSV = "cleaned_returns.csv"
RISK_FREE = float(os.environ.get("RISK_FREE_RATE", "0.0"))


returns = (
    pd.read_csv(RETURNS_CSV, index_col=0, parse_dates=True)
      .sort_index()
      .dropna(how="all", axis=1)
      .dropna(how="any")               
)


assert returns.shape[1] >= 2, "Need at least two assets"
print("Loaded returns shape:", returns.shape)


date_diffs = returns.index.to_series().diff().dt.days.dropna()
if date_diffs.median() <= 5:
    ANN = 252
elif date_diffs.median() <= 10:
    ANN = 52
else:
    ANN = 12
print(f"Assumed annualisation factor: {ANN}")


##had trouble with this and generated these helpers.

import numpy as np
import pandas as pd
import riskfolio as rp
import inspect

# --- Pure-Python HRP implementation (no Riskfolio APIs needed) ---
# Requires: scipy (already in your env from earlier steps)
from scipy.cluster.hierarchy import linkage, dendrogram
from scipy.spatial.distance import squareform

def _cov_corr(returns: pd.DataFrame):
    cov = returns.cov()
    std = np.sqrt(np.diag(cov))
    corr = cov / np.outer(std, std)
    corr[np.isnan(corr)] = 0.0
    corr = pd.DataFrame(corr, index=cov.index, columns=cov.columns)
    return cov, corr

def _get_quasi_diag(link):
    # Order clustered items via a top-down traversal of the linkage tree
    link = link.astype(int)
    sort_ix = pd.Series([link[-1, 0], link[-1, 1]])
    num_items = link[-1, 3]
    while sort_ix.max() >= num_items:
        sort_ix.index = range(0, sort_ix.shape[0]*2, 2)
        df0 = sort_ix[sort_ix >= num_items]
        i = df0.index
        j = df0.values - num_items
        sort_ix[i] = link[j, 0]
        df1 = pd.Series(link[j, 1], index=i + 1)
        sort_ix = pd.concat([sort_ix, df1]).sort_index()
        sort_ix.index = range(sort_ix.shape[0])
    return sort_ix.tolist()

def _get_ivp(cov):
    # Inverse-variance portfolio
    iv = 1.0 / np.diag(cov)
    w = iv / iv.sum()
    return w

def _get_cluster_var(cov, items):
    cov_ = cov.loc[items, items].values
    w = _get_ivp(cov_)
    return w.T @ cov_ @ w

def hrp_weights(returns: pd.DataFrame) -> pd.Series:
    """
    Hierarchical Risk Parity per LÃ³pez de Prado (2016).
    """
    assets = list(returns.columns)
    cov, corr = _cov_corr(returns)
    dist = np.sqrt(0.5 * (1.0 - corr))
    # SciPy needs condensed distance vector
    dist_vec = squareform(dist.values, checks=False)
    link = linkage(dist_vec, method='single')  # common choice for HRP
    sort_ix = _get_quasi_diag(link)
    sorted_assets = [assets[i] for i in sort_ix]

    weights = pd.Series(1.0, index=sorted_assets)
    clusters = [sorted_assets]

    # Recursive bisection
    while len(clusters) > 0:
        clusters_ = []
        for cluster in clusters:
            if len(cluster) == 1:
                continue
            split = len(cluster) // 2
            left = cluster[:split]
            right = cluster[split:]

            var_left = _get_cluster_var(cov, left)
            var_right = _get_cluster_var(cov, right)
            alpha = 1.0 - var_left / (var_left + var_right)

            weights[left] *= alpha
            weights[right] *= (1.0 - alpha)

            clusters_ += [left, right]
        clusters = clusters_

    # Reindex to original columns
    weights = weights.reindex(returns.columns).fillna(0.0)
    # Normalise to sum 1
    weights = weights / weights.sum()
    return weights

# --- Riskfolio helper that is API-robust and uses our HRP if needed ---
def _to_series(w, cols):
    if isinstance(w, pd.Series):
        s = w
    elif isinstance(w, pd.DataFrame):
        s = w.iloc[:, 0] if w.shape[1] > 0 else pd.Series(dtype=float)
    else:
        s = pd.Series(w, index=cols)
    return s.reindex(cols).fillna(0.0)

def riskfolio_mv_solutions(ret_df, rf=0.0, long_only=True, lower=None, upper=None):
    """
    Build several portfolios using riskfolio-lib (MV/MinVar/CVaR) and a
    pure-Python HRP fallback so it works across Riskfolio versions.

    Parameters
    ----------
    ret_df : DataFrame of asset returns
    rf : annual risk-free rate in decimal
    long_only : if True, enforce no shorting
    lower, upper : optional per-asset caps (floats). Used only if supported
                   by your installed Riskfolio API, otherwise ignored.

    Returns
    -------
    dict[name -> pd.Series(weights)]
    """
    port = rp.Portfolio(returns=ret_df)

    # Moments
    try:
        port.assets_stats(method_mu='hist', method_cov='ledoit')
    except Exception:
        port.assets_stats(method_mu='hist', method_cov='hist')

    # Build kwargs compatible with multiple riskfolio versions
    try:
        opt_sig = inspect.signature(rp.Portfolio.optimization)
        params = opt_sig.parameters
    except Exception:
        params = {}

    common = dict(rf=rf, l=0)
    if 'budget' in params:
        common['budget'] = 1
    if 'short' in params:
        common['short'] = (not long_only)

    # Try explicit bounds if supported
    bounds_added = False
    if lower is not None and upper is not None:
        n = ret_df.shape[1]
        b = np.array([[float(lower), float(upper)]] * n)
        if 'b' in params:
            common['b'] = b
            bounds_added = True
        elif 'bounds' in params:
            common['bounds'] = b
            bounds_added = True
    if (lower is not None or upper is not None) and not bounds_added:
        print("[note] Bounds not supported by your riskfolio build. Using long_only + budget constraints.")

    sols = {}

    # MV Max-Sharpe
    w_mv = port.optimization(model='Classic', rm='MV', obj='Sharpe', **common)
    sols["MV_MaxSharpe"] = _to_series(w_mv, ret_df.columns)

    # MV Min-Variance
    w_min = port.optimization(model='Classic', rm='MV', obj='MinRisk', **common)
    sols["MV_MinVar"] = _to_series(w_min, ret_df.columns)

    # CVaR Min-Risk
    w_cvar = port.optimization(model='Classic', rm='CVaR', obj='MinRisk', **common)
    sols["CVaR_MinRisk"] = _to_series(w_cvar, ret_df.columns)

    # HRP: try Riskfolio convenience, else our pure-Python HRP
    try:
        # If your version happens to have this:
        w_hrp = rp.hrp_portfolio(returns=ret_df, codependence='pearson')  # may raise AttributeError
        sols["HRP"] = _to_series(w_hrp, ret_df.columns)
    except Exception:
        sols["HRP"] = hrp_weights(ret_df)

    return sols


solutions = riskfolio_mv_solutions(returns, rf=RISK_FREE, long_only=True)
solutions["HRP"].sort_values(ascending=False).head(10)


print("\nOptimised weight vectors (top 10 by weight):")
for name, w in solutions.items():
    print(f"\n{name}")
    print(w.sort_values(ascending=False).head(10).round(4))


try:
    fig = rp.plot_pie(
        w=solutions["MV_MaxSharpe"],
        title="Weights - MV Max Sharpe",
        others=0.02, nrow=25, height=6, width=10
    )
    plt.show()
except Exception as e:
    print("Plot skipped:", e)


def portfolio_returns(ret_df, weights):
    w = weights.reindex(ret_df.columns).fillna(0.0)
    return (ret_df @ w).rename("strategy")

def perf_stats(r, ann=252, rf=0.0):
    r = r.dropna()
    cum = (1 + r).prod() - 1
    mean = r.mean() * ann
    vol = r.std(ddof=1) * np.sqrt(ann)
    sharpe = (mean - rf) / vol if vol > 0 else np.nan
    wealth = (1 + r).cumprod()
    peak = wealth.cummax()
    mdd = ((wealth / peak) - 1).min()
    return pd.Series({
        "Cumulative Return": cum,
        "Annual Return": mean,
        "Annual Volatility": vol,
        "Sharpe": sharpe,
        "Max Drawdown": mdd
    })


static_results = {}
for name, w in solutions.items():
    sr = portfolio_returns(returns, w)
    static_results[name] = perf_stats(sr, ann=ANN, rf=RISK_FREE)


print("\nStatic strategy performance:")
print(pd.DataFrame(static_results).round(4))


def rolling_backtest(ret_df, lookback_months=36, rebalance='M', model_name="MV_MaxSharpe", rf=0.0):
    """
    Rolling optimisation:
    - Rebalance on each period end (rebalance frequency).
    - Fit using lookback_months of trailing data up to prior period end.
    - Apply weights for the next period.
    """
    ret_df = ret_df.copy()
    rebal_dates = ret_df.resample(rebalance).last().index
    strat_rets = []

    for i in range(1, len(rebal_dates)):
        end = rebal_dates[i-1]
        start = (end - pd.DateOffset(months=lookback_months)) + pd.offsets.MonthBegin(0)
        in_sample = ret_df.loc[start:end].dropna(how="any")

        # Require some minimum sample to estimate moments
        if in_sample.shape[0] < max(lookback_months - 3, 12):
            continue

        sols = riskfolio_mv_solutions(in_sample, rf=rf, long_only=True)
        w = sols.get(model_name, sols["MV_MaxSharpe"])

        next_start = rebal_dates[i-1] + pd.Timedelta(days=1)
        next_end = rebal_dates[i]
        out_sample = ret_df.loc[next_start:next_end]
        if out_sample.empty:
            continue

        pr = portfolio_returns(out_sample, w)
        strat_rets.append(pr)

    if len(strat_rets) == 0:
        raise ValueError("No out of sample periods. Check lookback or data frequency.")

    out = pd.concat(strat_rets).sort_index()
    return out


print("\nRunning rolling backtest - MV_MaxSharpe, 36 month lookback, monthly rebalance...")
rolling_rets = rolling_backtest(returns, lookback_months=36, rebalance='M',
                                model_name="MV_MaxSharpe", rf=RISK_FREE)
print("Rolling sample length:", rolling_rets.shape[0])


roll_stats = perf_stats(rolling_rets, ann=ANN, rf=RISK_FREE)
print("\nRolling backtest performance:")
print(roll_stats.round(4))


(1 + rolling_rets).cumprod().plot(title="Rolling MV Max Sharpe - cumulative wealth")
plt.xlabel("Date")
plt.ylabel("Wealth")
plt.show()


try:
    import pyfolio as pf
    pf.create_returns_tear_sheet(rolling_rets, return_fig=True)
    plt.show()
except Exception as e:
    print("PyFolio tear sheet skipped:", e)



